{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Similarity\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<b>\n",
    "\"Two points in a sparse region are more similar than two points of equal inter-point distance in a dense region\"\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "[arXiv:1907.00378v1]\n",
    "</div>\n",
    "\n",
    "In this work I implemented Isolation Kernel (Similarity) using iForest and aNNE. Isolation Kernel is described in the article \"Nearest-Neighbour-Induced Isolation Similarity and Its Impact on Density-Based Clustering\" [arXiv:1907.00378v1](https://arxiv.org/pdf/1907.00378.pdf). I used datasets \"jain\" and \"pathbased\" from [cs.uef.fi](http://cs.uef.fi/sipu/datasets) and \"Breast Cancer Wisconsin (Diagnostic)\" from [archive.ics.uci.edu](https://archive.ics.uci.edu/ml/datasets).\n",
    "Algorithm MBSCAN based on iForest- and aNNE-Dissimilarity are compared with DBSCAN, SpectralClustering, AgglomerativeClustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "\n",
    "! wget http://cs.uef.fi/sipu/datasets/jain.txt\n",
    "\n",
    "! wget http://cs.uef.fi/sipu/datasets/pathbased.txt\n",
    "\n",
    "! wget -r -nH --cut-dirs=2 -np -R \"index.html*\" https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, let's load datasets and normalize them using the min-max normalisation so that each attribute is in [0, 1] before the experiments begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def load_wdbc_dataset():\n",
    "    dataset = pd.read_csv('breast-cancer-wisconsin/wdbc.data', header=None, index_col=0)\n",
    "\n",
    "    data = dataset.drop(dataset.columns[0], axis=1)\n",
    "    target = dataset[dataset.columns[0]].replace('B', 1).replace('M', 0)\n",
    "\n",
    "    # min-max scaling\n",
    "    data = pd.DataFrame(MinMaxScaler().fit_transform(data), data.index)\n",
    "    \n",
    "    return data, target\n",
    "\n",
    "\n",
    "def load_jain_dataset():\n",
    "    dataset = open('jain.txt').read().splitlines()\n",
    "    dataset = pd.DataFrame(list(map(lambda x: list(map(float, x.split('\\t'))), dataset)))\n",
    "\n",
    "    data = dataset.drop(dataset.columns[-1], axis=1)\n",
    "    target = dataset[dataset.columns[-1]].astype(int).replace(2, 0)\n",
    "\n",
    "    # min-max scaling\n",
    "    data = pd.DataFrame(MinMaxScaler().fit_transform(data), data.index)\n",
    "\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def load_pathbased_dataset():\n",
    "    dataset = open('pathbased.txt').read().splitlines()\n",
    "    dataset = pd.DataFrame(list(map(lambda x: list(map(float, x.split('\\t'))), dataset)))\n",
    "\n",
    "    data = dataset.drop(dataset.columns[-1], axis=1)\n",
    "    target = dataset[dataset.columns[-1]].astype(str).replace('1.0', 2).replace('2.0', 1).replace('3.0', 0)\n",
    "\n",
    "    # min-max scaling\n",
    "    data = pd.DataFrame(MinMaxScaler().fit_transform(data), data.index)\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset \"Breast Cancer Wisconsin (Diagnostic)\" has 30 features and 569 objects which are devided by 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5   \\\n",
       "0                                                                      \n",
       "842302    0.521037  0.022658  0.545989  0.363733  0.593753  0.792037   \n",
       "842517    0.643144  0.272574  0.615783  0.501591  0.289880  0.181768   \n",
       "84300903  0.601496  0.390260  0.595743  0.449417  0.514309  0.431017   \n",
       "84348301  0.210090  0.360839  0.233501  0.102906  0.811321  0.811361   \n",
       "84358402  0.629893  0.156578  0.630986  0.489290  0.430351  0.347893   \n",
       "\n",
       "                6         7         8         9   ...        20        21  \\\n",
       "0                                                 ...                       \n",
       "842302    0.703140  0.731113  0.686364  0.605518  ...  0.620776  0.141525   \n",
       "842517    0.203608  0.348757  0.379798  0.141323  ...  0.606901  0.303571   \n",
       "84300903  0.462512  0.635686  0.509596  0.211247  ...  0.556386  0.360075   \n",
       "84348301  0.565604  0.522863  0.776263  1.000000  ...  0.248310  0.385928   \n",
       "84358402  0.463918  0.518390  0.378283  0.186816  ...  0.519744  0.123934   \n",
       "\n",
       "                22        23        24        25        26        27  \\\n",
       "0                                                                      \n",
       "842302    0.668310  0.450698  0.601136  0.619292  0.568610  0.912027   \n",
       "842517    0.539818  0.435214  0.347553  0.154563  0.192971  0.639175   \n",
       "84300903  0.508442  0.374508  0.483590  0.385375  0.359744  0.835052   \n",
       "84348301  0.241347  0.094008  0.915472  0.814012  0.548642  0.884880   \n",
       "84358402  0.506948  0.341575  0.437364  0.172415  0.319489  0.558419   \n",
       "\n",
       "                28        29  \n",
       "0                             \n",
       "842302    0.598462  0.418864  \n",
       "842517    0.233590  0.222878  \n",
       "84300903  0.403706  0.213433  \n",
       "84348301  1.000000  0.773711  \n",
       "84358402  0.157500  0.142595  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wdbc_dat, wdbc_tar = load_wdbc_dataset()\n",
    "display(wdbc_dat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset \"jain\" has 2 features and 373 objects devided by 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.582329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062885</td>\n",
       "      <td>0.502008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.110974</td>\n",
       "      <td>0.451807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102343</td>\n",
       "      <td>0.510040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.002466  0.582329\n",
       "1  0.000000  0.508032\n",
       "2  0.062885  0.502008\n",
       "3  0.110974  0.451807\n",
       "4  0.102343  0.510040"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jain_dat, jain_tar = load_jain_dataset()\n",
    "display(jain_dat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset \"pathbased\" has 2 features and 300 objects devided by 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231041</td>\n",
       "      <td>0.049822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220459</td>\n",
       "      <td>0.037367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181658</td>\n",
       "      <td>0.076512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.179894</td>\n",
       "      <td>0.074733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156966</td>\n",
       "      <td>0.112100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.231041  0.049822\n",
       "1  0.220459  0.037367\n",
       "2  0.181658  0.076512\n",
       "3  0.179894  0.074733\n",
       "4  0.156966  0.112100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pathbased_dat, pathbased_tar = load_pathbased_dataset()\n",
    "display(pathbased_dat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build Isolation Kernel, first, we need to select subsample $D_i'$ of sample $D'$ randomly where $i = 1 \\dots t$ and $|D_i'| = \\psi$.\n",
    "Secondly, we denote the set of all partitions $H_i$ that are admissible under $D$ where each isolating partition $\\Theta \\in H_i$ isolates one data point from the rest of the points in a random subset $D_i' \\in D$.\n",
    "Thirdly, for all pairs $x, y$ of points from the sample we define value\n",
    "$$ K_{\\psi}(x, y | D) = \\frac{1}{t}\\sum_{i=1}^t I(x, y \\in \\Theta | \\Theta \\in H_i) $$\n",
    "as an element of Isolation Kernel matrix.\n",
    "\n",
    "Following on from this, let's define Isolation Dissimilarity as $p(x, y) = 1 − K_{\\psi}(x, y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's realize the function that builds iForest-Dissimilarity.\n",
    "The autors of the article reveal two shortcomings in using isolation trees.\n",
    "The first one is that each isolation tree employs axis-parallel splits.\n",
    "The second one is an imbalanced tree.\n",
    "Some partitions are always overextended for the first few splits close to the root of an imbalanced tree and these are manifested as elongated rectangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "def get_iForestDissimilarity(dataset, psi, t):\n",
    "    similarity = []\n",
    "\n",
    "    for _ in range(t):\n",
    "        # generate random subset\n",
    "        subset = np.random.choice(range(dataset.shape[0]), psi)\n",
    "\n",
    "        # fit iForest on the generated subset\n",
    "        iForest = IsolationForest(n_estimators=1)\n",
    "        iForest.fit(dataset.iloc[subset])\n",
    "\n",
    "        # for each object get its leaf\n",
    "        leaves = iForest.estimators_[0].apply(dataset)\n",
    "\n",
    "        # produce isolation kernel\n",
    "        K = np.array([int(leaves[i] == leaves[j]) for i in range(len(leaves)) for j in range(len(leaves))])\n",
    "        \n",
    "        similarity.append(K.reshape((len(leaves), len(leaves))))\n",
    "\n",
    "    return 1 - np.mean(np.array(similarity), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's realize the function that builds aNNE-Dissimilarity.\n",
    "The partitions here are cells in Voronoi diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aNNEDissimilarity(dataset, psi, distance_matrix, t):\n",
    "    similarity = []\n",
    "\n",
    "    for _ in range(t):\n",
    "        # generate random subset\n",
    "        subset = np.random.choice(range(dataset.shape[0]), psi)\n",
    "\n",
    "        # calculate distance to each cell's center\n",
    "        cells = np.argmin(distance_matrix[subset], axis=0)\n",
    "\n",
    "        # produce isolation kernel\n",
    "        K = np.array([int(cells[i] == cells[j]) for i in range(len(cells)) for j in range(len(cells))])\n",
    "        \n",
    "        similarity.append(K.reshape((len(cells), len(cells))))\n",
    "\n",
    "    return 1 - np.mean(np.array(similarity), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is function of computing distance matrix, we will use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(data):\n",
    "    distance_matrix = np.zeros((data.shape[0], data.shape[0]))\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[0]):\n",
    "            distance_matrix[i, j] = np.linalg.norm(data.values[i] - data.values[j])\n",
    "\n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to use computed Dissimilarities.\n",
    "For this we apply algorithm MBSCAN, which is DBSCAN that we fit on Isolation Dissimilarity matrix with metric equal to \"precomputed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def grid_search(data, target, t=200):\n",
    "    \"\"\"\n",
    "    eps    in [0.01, ..., 0.99]\n",
    "    minPts in [2, ..., 40]\n",
    "    psi    in [10 values from 2 to len(data) // 2]\n",
    "    \"\"\"\n",
    "\n",
    "    dbscan, mbscan_iForest, mbscan_aNNE = [], [], []\n",
    "\n",
    "    # generate list of params\n",
    "    eps_minPts_list = [(eps, minPts) for eps in np.linspace(0, 1, 101)[1:-1] for minPts in range(2, 41)]\n",
    "    psi_list = np.linspace(2, data.shape[0] // 2, 10).astype(int)\n",
    "\n",
    "    # calculate distance matrix\n",
    "    distance_matrix = get_distance_matrix(data)\n",
    "\n",
    "    # calculate dissimilarities for each psi from psi_list\n",
    "    iForestDissimilarities, aNNEDissimilarities = [], []\n",
    "    for psi in tqdm(psi_list, desc='Calculating of isolation dissimilarities'):\n",
    "        iForestDissimilarities.append(get_iForestDissimilarity(data, psi=psi, t=t))\n",
    "        aNNEDissimilarities.append(get_aNNEDissimilarity(data, psi=psi, distance_matrix=distance_matrix, t=t))\n",
    "\n",
    "    # searching for clustering params\n",
    "    for eps, minPts in tqdm(eps_minPts_list, desc='Searching for clustering params'):\n",
    "        # clusterize dataset using DBSCAN\n",
    "        preds = DBSCAN(eps=eps, min_samples=minPts).fit_predict(data)\n",
    "        score = f1_score(target, preds, average='macro', labels=np.unique(target))\n",
    "        dbscan.append([round(score, 3), eps, minPts, '-'])\n",
    "\n",
    "        for psi, iForestDissimilarity, aNNEDissimilarity in zip(psi_list, iForestDissimilarities, aNNEDissimilarities):\n",
    "                # clusterize dataset using MBSCAN-iForest\n",
    "                preds = DBSCAN(eps=eps, min_samples=minPts, metric='precomputed').fit_predict(iForestDissimilarity)\n",
    "                score = f1_score(target, preds, average='macro', labels=np.unique(target))\n",
    "                mbscan_iForest.append([round(score, 3), eps, minPts, psi])\n",
    "\n",
    "                # clusterize dataset using MBSCAN-aNNE\n",
    "                preds = DBSCAN(eps=eps, min_samples=minPts, metric='precomputed').fit_predict(aNNEDissimilarity)\n",
    "                score = f1_score(target, preds, average='macro', labels=np.unique(target))\n",
    "                mbscan_aNNE.append([round(score, 3), eps, minPts, psi])\n",
    "\n",
    "    best = [max(clr, key=lambda x: x[0]) for clr in [dbscan, mbscan_iForest, mbscan_aNNE]]\n",
    "    result = pd.DataFrame(data=best,\n",
    "                          columns=['F1', 'eps', 'min_samples', 'psi'],\n",
    "                          index=['dbscan', 'mbscan_iForest', 'mbscan_aNNE'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating of isolation dissimilarities: 100%|██████████| 10/10 [35:26<00:00, 212.67s/it]\n",
      "Searching of clustering params: 100%|██████████| 3861/3861 [17:55<00:00,  3.59it/s]\n"
     ]
    }
   ],
   "source": [
    "wdbc_res = grid_search(wdbc_dat, wdbc_tar, t=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating of isolation dissimilarities: 100%|██████████| 10/10 [13:40<00:00, 82.01s/it]\n",
      "Searching of clustering params: 100%|██████████| 3861/3861 [12:03<00:00,  5.34it/s]\n"
     ]
    }
   ],
   "source": [
    "jain_res = grid_search(jain_dat, jain_tar, t=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating of isolation dissimilarities: 100%|██████████| 10/10 [10:41<00:00, 64.15s/it]\n",
      "Searching of clustering params: 100%|██████████| 3861/3861 [08:48<00:00,  7.30it/s]\n"
     ]
    }
   ],
   "source": [
    "pathbased_res = grid_search(pathbased_dat, pathbased_tar, t=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the result of dataset \"wdbc\" clustering by algorithms dbscan, mbscan_iForest and mbscan_aNNE.\n",
    "For quality assessments, the F1 metric with \"macro\" averange is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dbscan</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.40</td>\n",
       "      <td>13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbscan_iForest</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.18</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbscan_aNNE</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.67</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F1   eps  min_samples psi\n",
       "dbscan          0.577  0.40           13   -\n",
       "mbscan_iForest  0.906  0.18           33   2\n",
       "mbscan_aNNE     0.930  0.67           17  33"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdbc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the result of dataset \"jain\" clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dbscan</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.12</td>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbscan_iForest</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbscan_aNNE</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F1   eps  min_samples psi\n",
       "dbscan          0.828  0.12           23   -\n",
       "mbscan_iForest  1.000  0.31            2  22\n",
       "mbscan_aNNE     1.000  0.40            2  22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jain_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the result of dataset \"pathbased\" clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dbscan</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbscan_iForest</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.51</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbscan_aNNE</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F1   eps  min_samples  psi\n",
       "dbscan          0.699  0.07            9    -\n",
       "mbscan_iForest  0.747  0.51           13   34\n",
       "mbscan_aNNE     0.988  0.80            7  100"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathbased_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's try to clusterize our datasets by other clustering algorithms, for example, SpectralClustering and AgglomerativeClustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering\n",
    "\n",
    "\n",
    "def clustering(data, target):\n",
    "    result = []\n",
    "    target = target.astype(str).replace('2', 1).replace('1', 2).astype(int) if len(np.unique(target)) == 3 else target\n",
    "    \n",
    "    # clusterize dataset using SpectralClustering\n",
    "    preds = SpectralClustering(n_clusters=len(np.unique(target))).fit_predict(data)\n",
    "    score = f1_score(target, preds, average='macro', labels=np.unique(target))\n",
    "    result.append([round(score, 3)])\n",
    "\n",
    "    # clusterize dataset using AgglomerativeClustering\n",
    "    preds = AgglomerativeClustering(n_clusters=len(np.unique(target))).fit_predict(data)\n",
    "    score = f1_score(target, preds, average='macro', labels=np.unique(target))\n",
    "    result.append([round(score, 3)])\n",
    "\n",
    "    return pd.DataFrame(data=result,\n",
    "                        columns=['F1'],\n",
    "                        index=['spectral_clustering', 'agglomerative_clustering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc_add_res = clustering(wdbc_dat, wdbc_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "jain_add_res = clustering(jain_dat, jain_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathbased_add_res = clustering(pathbased_dat, pathbased_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b531f960_1c42_11eb_944d_98fe9442afberow0_col2,#T_b531f960_1c42_11eb_944d_98fe9442afberow0_col3,#T_b531f960_1c42_11eb_944d_98fe9442afberow1_col2,#T_b531f960_1c42_11eb_944d_98fe9442afberow2_col2{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_b531f960_1c42_11eb_944d_98fe9442afbe\" ><thead>    <tr>        <th class=\"index_name level0\" >algorithm</th>        <th class=\"col_heading level0 col0\" >agglomerative_clustering</th>        <th class=\"col_heading level0 col1\" >dbscan</th>        <th class=\"col_heading level0 col2\" >mbscan_aNNE</th>        <th class=\"col_heading level0 col3\" >mbscan_iForest</th>        <th class=\"col_heading level0 col4\" >spectral_clustering</th>    </tr>    <tr>        <th class=\"index_name level0\" >dataset</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b531f960_1c42_11eb_944d_98fe9442afbelevel0_row0\" class=\"row_heading level0 row0\" >jain</th>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow0_col0\" class=\"data row0 col0\" >0.769000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow0_col1\" class=\"data row0 col1\" >0.828000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow0_col4\" class=\"data row0 col4\" >0.870000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b531f960_1c42_11eb_944d_98fe9442afbelevel0_row1\" class=\"row_heading level0 row1\" >pathbased</th>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow1_col0\" class=\"data row1 col0\" >0.732000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow1_col1\" class=\"data row1 col1\" >0.699000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow1_col2\" class=\"data row1 col2\" >0.988000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow1_col3\" class=\"data row1 col3\" >0.747000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow1_col4\" class=\"data row1 col4\" >0.732000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b531f960_1c42_11eb_944d_98fe9442afbelevel0_row2\" class=\"row_heading level0 row2\" >wdbc</th>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow2_col0\" class=\"data row2 col0\" >0.856000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow2_col1\" class=\"data row2 col1\" >0.577000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow2_col2\" class=\"data row2 col2\" >0.930000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow2_col3\" class=\"data row2 col3\" >0.906000</td>\n",
       "                        <td id=\"T_b531f960_1c42_11eb_944d_98fe9442afberow2_col4\" class=\"data row2 col4\" >0.830000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12618c5e0>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: lightgreen' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "wdbc = pd.concat([wdbc_res[['F1']], wdbc_add_res])\n",
    "wdbc['dataset'] = 'wdbc'\n",
    "\n",
    "jain = pd.concat([jain_res[['F1']], jain_add_res])\n",
    "jain['dataset'] = 'jain'\n",
    "\n",
    "pathbased = pd.concat([pathbased_res[['F1']], pathbased_add_res])\n",
    "pathbased['dataset'] = 'pathbased'\n",
    "\n",
    "result = pd.concat([wdbc, jain, pathbased])\n",
    "result.index.name = 'algorithm'\n",
    "\n",
    "pd.pivot_table(result.reset_index(), values='F1', index='dataset', columns='algorithm').style.apply(highlight_max,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the best algorithm on all datasets is algorithm based on Isolation Kernel – MBSCAN-aNNE.\n",
    "The second algorithm in terms of quality is another one based on Isolation Kernel – MBSCAN-iForest.\n",
    "\n",
    "To summarize, Isolation Similarity is indeed a realy good approach of Density-Based Clustering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
